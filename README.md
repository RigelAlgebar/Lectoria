# Lectoria

_Lectoria es una aplicaci√≥n que le permite a tu empresa superar los procesos manuales ofreciendo
la extraci√≥n y el an√°lisis de documentos escaneados de manera autom√°tica._

## Comenzando üöÄ.

¬øC√≥mo funciona?

Lector√≠a le permite al usuario ingresar im√°genes dentro de la aplicaci√≥n, dentro de √©sta el lector de im√°genes la procesa y extrae la informaci√≥n requerida por el usuario. 

En este proyecto estamos extrayendo 12 cuentas de los Estados Financieros


| Balance General   | Estado de p√©rdidas y ganancias | General            |  
|-------------------|--------------------------------|--------------------|
| *Caja y efectivo  | *Ventas                        | *Fecha              |   
| *Total Pasivo     | *Costo de Ventas               | *Unidades de medida |   
| *Total Patrimonio | *Utilidad Bruta                |                    |   
|                   | *Utilidad operacional          |                    |   
|                   | *Utilidad antes de impuestos   |                    |   
|                   | *Utilidad neta                 |                    |  





Despu√©s de extraer la informaci√≥n se genera un archivo .csv y adicional dentro de la misma aplicaci√≥n puedes acceder a un dashboard din√°mico que contiene anal√≠ticos generados
con la informaci√≥n de los archivos ingresados por el usuario



![title](src/static/images/diagrama.png)


------------





## Construido con üõ†Ô∏è

_Las herramientas utilizadas son las siguientes_

* [Amazon Textract](https://aws.amazon.com/es/textract/) Lector de im√°genes
* [AWS S3](https://aws.amazon.com/es/s3/) Almacenamiento
* [AWS EC2](https://aws.amazon.com/es/ec2/) Procesamiento
* [Streamlit](https://www.streamlit.io/) app framework



### Pre-requisitos üìã


Herramientas requeridas para la aplicaci√≥n

*Python 3.7 https://www.python.org/downloads/
*Usuario de Amazon web services https://aws.amazon.com/es/



### Instalaci√≥n üîß

_Instalaciones requeridas para la aplicaci√≥n_

```
pip install streamlit
```
```
pip install awesome-streamlit
```
```
pip install altair
```
```
pip install plotly
```
```
pip install boto3
```



## Contribuyendo üñáÔ∏è

Este proyecto es parte de la competencia de programaci√≥n global creada por BBVA 

https://openinnovation.bbva.com/es/retos-2020


[![IMAGE ALT TEXT](src/static/images/hackaton.JPG)](https://www.youtube.com/watch?v=G7ykOxP2Glg&feature=emb_title "Hackaton BBVA")






    ‚îú‚îÄ‚îÄ LICENSE
    ‚îú‚îÄ‚îÄ Makefile           <- Makefile with commands like `make data` or `make train`
    ‚îú‚îÄ‚îÄ README.md          <- The top-level README for developers using this project.
    ‚îú‚îÄ‚îÄ data
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ external       <- Data from third party sources.
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ interim        <- Intermediate data that has been transformed.
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ processed      <- The final, canonical data sets for modeling.
    ```
Da un ejemplo
```
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ raw            <- The original, immutable data dump.
    ‚îÇ
    ‚îú‚îÄ‚îÄ docs               <- A default Sphinx project; see sphinx-doc.org for details
    ‚îÇ
    ‚îú‚îÄ‚îÄ models             <- Trained and serialized models, model predictions, or model summaries
    ‚îÇ
    ‚îú‚îÄ‚îÄ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
    ‚îÇ                         the creator's initials, and a short `-` delimited description, e.g.
    ‚îÇ                         `1.0-jqp-initial-data-exploration`.
    ‚îÇ
    ‚îú‚îÄ‚îÄ references         <- Data dictionaries, manuals, and all other explanatory materials.
    ‚îÇ
    ‚îú‚îÄ‚îÄ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ figures        <- Generated graphics and figures to be used in reporting
    ‚îÇ
    ‚îú‚îÄ‚îÄ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
    ‚îÇ                         generated with `pip freeze > requirements.txt`
    ‚îÇ
    ‚îú‚îÄ‚îÄ setup.py           <- makes project pip installable (pip install -e .) so src can be imported
    ‚îú‚îÄ‚îÄ src                <- Source code for use in this project.
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.py    <- Makes src a Python module
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ data           <- Scripts to download or generate data
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ make_dataset.py
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ features       <- Scripts to turn raw data into features for modeling
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ build_features.py
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ models         <- Scripts to train models and then use trained models to make
    ‚îÇ   ‚îÇ   ‚îÇ                 predictions
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ predict_model.py
    ‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ train_model.py
    ‚îÇ   ‚îÇ
    ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ visualization  <- Scripts to create exploratory and results oriented visualizations
    ‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ visualize.py
    ‚îÇ
    ‚îî‚îÄ‚îÄ tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io


--------

<p><small>Project based on the <a target="_blank" href="https://drivendata.github.io/cookiecutter-data-science/">cookiecutter data science project template</a>. #cookiecutterdatascience</small></p>
